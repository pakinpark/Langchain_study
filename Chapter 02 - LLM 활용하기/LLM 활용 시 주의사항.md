LLM은 보안 및 규제 측면에서 제약이 많아 아래의 사항을 고려하여 사용해야 한다. 


1. 정보 필터링

LLM을 이용하는 사용자의 질문은 반드시 필터링을 해야 한다. 특히 개인정보가 입력되지 않도록 필터링 하는 것이 중요하다. 

ex) 개인정보가 감지되면 제거하거나 변경

 

2. 할루시네이션

할루시네이션은 AI중 특히나 언어 모델이 부정확하거나 관련 없는 정보를 생성하는 현상을 가리킨다. 

할루시네이션은 정보 검색 결과만 정확하다면 어느정도 해결할 수 있다. 

또한 LLM 구현 과정 중 마지막에 할루시네이션 필터링을 추가함으로써 할루시네이션을 방지할 수 있다. 

 

3. 편향과 공정성

LLM은 학습된 데이터가 공정하지 못하다면, 모델 또한 공정하지 못한 결과를 뱉어낸다. 

 

4. 투명성

LLM은 대답을 하는 이유에 대해 사용자에게 설명하는 능력이 부족하다. 
