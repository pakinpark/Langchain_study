# 1. 언어모델의 단계

통계적 언어 모델 → 신경망 언어 모델 → 트랜스포머

## 통계적 언어 모델

초기의 언어 모델로 컴퓨터가 문장이나 단어를 얼마나 자연스럽게 표현할지를 수학적으로 계산하는 통계적 방법에 기반했다. 확률/통계적 방법의 대표로는 'n-gram'이 있다. 



""n-gram"" : 일련의 단어나 문자가 얼마나 자주 함께 나타나는지를 살펴보는 방법으로, 몇 개의 단어로 나누는지에 따라 1-gram, 2-gram, 3-gram 으로 나눈다. BUT 데이터베이스를 사전에 만들어두어야 하는 번거로운 작업과, n이 커질수록 문맥을 제대로 이해하지 못하는 단점이있다.  

- 1-gram(유니그램) : 전체 문장을 각각의 단어로 나눔 
- 2-gram(바이그램) : 전체 문장을 두 단어씩 나눔
- 3-gram(트라이그램) : 전체 문장을 세 단어씩 나눔
※ 여기서 바이그램과 트라이그램은 단어가 중복됨!


## 신경망 언어 모델

머신러닝이 발전하며 나온 언어모델로, 인간의 신경세포(뉴런)이 서로 연결되어 정보를 처리하는 방식을 본 따서 만들어졌다. 이는 데이터에서 복잡한 패턴을 학습해 문제를 해결하는 데 활용된다. 신경망은 입력층, 은닉층, 출력층으로 구성되었고 각 계층에는 여러 뉴런이 있으며, 이들은 서로 연결되어 있다. 

- 입력층 : 외부로부터 데이터를 받아들임
- 은닉층 : 데이터를 처리하여 다양한 특성과 패턴을 학습
- 출력층  : 최종 결과를 생성

신경망 언어 모델에는 RNN, LSTM 등이 있다. 

### RNN(Recurrent Neural Networks) 

시퀀스 데이터 처리에 적합하며 과거의 정보가 현재의 결정에 영향을 미칠 수 있다. 변화하는 데이터를 분석해 미래를 예측할 수 있으나 과거의 데이터를 저장하기 위한 공간이 작아 긴 데이터를 처리하기엔 어렵다.

### LSTM(Logn Short-Term Momory Networks) 

긴 시퀀스 정보를 기억하고 필요에 따라 이를 삭제하거나 업데이트 하는 메커니즘을 가지고 있다. RNN은 과거 데이터를 기억하는 메모리 하나만을 보유한 것에 비해, LSTM은 장기 기억을 기억하는 메모리까지 2개를 보유하고 있다. 


## 트랜스포머 

각 단어나 구절을 개별적으로 이해하고 처리하는 이전 언어 모델들과 달리 문장과 단락 전체를 처리하는 언어 모델이다. 트랜스포머를 통해 LLM은 콘텐츠 생성, 문장 요약 등으로 활용 범위가 넓어졌다. 대표적인 모델로는 버트가 있다. 

### BERT(Bidirectional Encoder Representation from Transformers) 

텍스트를 양방향으로 분석하여 맥락을 이해하는 언어 모델로, 좀 더 자연스럽고 정확한 의미 파악이 가능해졌다. 
       ※ 양방향으로 ? : 앞 뒤 문맥을 모두 고려하여 그 단어의 의미를 이해한다! 

### GPT(Generatvie Pretrained Transformer) 

오픈 AI에 개발된 인간의 언어를 처리하는 인공지능 언어 모델이다. 

---


# 2. LLM 이란?

LLM(Large Language Model)은 인간의 언어를 처리하는 모델이다. → 언어모델! 

이는 대규모 데이터로 훈련된 매우 큰 규모의 인공지능 기반 언어 모델이다. 이는 대규모 데이터로 학습하고, 모델의 크기도 커야 한다. LLM의 대표적인 예로는 오픈AI의 GPT, 구글의 버트, 제미나이, Trubo 등이 있다. 

※ 여기서 대규모란? : 오픈 AI는 GPT-3 모델을 학습시킬 때 45TB의 텍스트 데이터를 학습시켰다고 한다. 

## LLM의 특징

1. 방대한 양의 텍스트 데이터로부터 학습한다.
2. 언어를 이해하고 생성하는 데 특화되어 있다. 
3. 특정 작업을 위해 파인튜닝을 할 수 있다. 
   ※ 파인튜닝이란 ? : 언어 모델을 기업의 데이터로 추가 학습을 시키는 과정으로, 특화된 분야에 더욱 정교하게 사용할 수 있다. 
4. LLM을 훈련하고 운영할 때 상당한 컴퓨팅 자원(GPU, TPU)이 필요하다. (https://yozm.wishket.com/magazine/detail/2294/ 왜 GPU일까? 싶은 경우 읽어보기 추천드리는 글) (TPU는 구글이 개발한 머신러닝 및 딥러닝 작업에 최적화된 하드웨어)
5. 질문은 프롬프트, 답변은 컴플리션이라고 부른다. 

LLM은 인프라스트럭처 레이어와, 애플리케이션 레이어로 구분할 수 있다. 


## 인프라스트럭처 레이어

하드웨어 회사와 모델 제공, 제공하는 모델을 빠르고 쉽게 구현하기 위한 클라우드 서비스 기업 등이 있다. 

- Model Creation
- Hardware
- Fine Tuning
- Interface

## 애플리케이션 레이어

이는 코드로 구현할 수 있는 프레임워크와 서비스로 활용할 수 있는 BI툴 제공 회사들이 있다. 

- Copywriting
- Coding
- Dev Tools
- Chat
- BizOps

---

# 3. 주요 LLM 모델

## GPT-4

오픈 AI가 23년 12월 발표한 모델로, 1조 5천억개의 파라미터를 갖는다. 복잡한 언어 패턴을 식별하여 텍스트 생성, 이해 및 일관된 문맥을 제공한다. 

GPT-4부터 멀티모달을 제공하는데, 이는 단일 텍스트가 아닌, 오디오 비디오 이미지 등의 여러 종류의 정보 처리를 제공하는 것이다. 

## 라마2
이는 메타가 개발한 LLM으로, 트랜스포머 아키텍처를 기반으로 만들어졌다. 오픈소스 모델인 점이 강점! 또한 경량 모델인 SLM(Small Languabe Model)또한 제공한다. 



